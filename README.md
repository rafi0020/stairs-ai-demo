# ğŸ¬ Stairs-AI Demo

> **Interactive ML Pipeline Visualization for Staircase Safety Monitoring**

[![Live Demo](https://img.shields.io/badge/Demo-Live-success?style=for-the-badge)](https://YOUR_USERNAME.github.io/stairs-ai-demo/)
[![License: MIT](https://img.shields.io/badge/License-MIT-blue.svg?style=for-the-badge)](LICENSE)
[![TypeScript](https://img.shields.io/badge/TypeScript-5.2-blue?style=for-the-badge&logo=typescript)](https://www.typescriptlang.org/)
[![React](https://img.shields.io/badge/React-18-blue?style=for-the-badge&logo=react)](https://react.dev/)

An **interactive, real-time visualization** of a complete computer vision safety monitoring pipelineâ€”from YOLO detection through MediaPipe pose estimation to compliance event generation. Built to showcase ML transparency and pipeline explainability.

![Demo Screenshot](assets/demo-screenshot.png)

---

## ğŸ¯ What This Demonstrates

This system proves technical capability across the full computer vision stack:

| Component | Technology | Evidence |
|-----------|-----------|----------|
| **Object Detection** | YOLOv8n | Real-time person bounding boxes with confidence scores |
| **Pose Estimation** | MediaPipe | 33-landmark skeleton with wrist/ear keypoint tracking |
| **Spatial Analysis** | Polygon Hit-Testing | Point-in-polygon rail contact detection |
| **Heuristic Detection** | Distance Metrics | Phone usage detection via wrist-to-ear proximity |
| **State Management** | Debounced FSM | 0.55s debounce preventing detection flicker |
| **Event System** | Structured Logging | JSON events with evidence frame snapshots |
| **Real-Time UI** | React + TypeScript | Interactive pipeline visualization with live metrics |

---

## ğŸ—ï¸ System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        VIDEO INPUT                               â”‚
â”‚                    8-second sample @ 24fps                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PYTHON ML PIPELINE                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  1. YOLOv8 Detection    â†’ Person bounding boxes                 â”‚
â”‚  2. Crop & Resize       â†’ Isolated person images                â”‚
â”‚  3. MediaPipe Pose      â†’ 33 skeleton keypoints                 â”‚
â”‚  4. Rail Hit-Test       â†’ Wrist in handrail zone?               â”‚
â”‚  5. Phone Heuristic     â†’ Wrist-to-ear distance < 0.05?         â”‚
â”‚  6. State Machine       â†’ Debounced compliance transitions      â”‚
â”‚  7. Event Logger        â†’ JSON events + evidence frames         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    STATIC PAYLOAD                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â€¢ frame_packets.json   â†’ Per-frame detection data              â”‚
â”‚  â€¢ events.json          â†’ Compliance state changes              â”‚
â”‚  â€¢ summary.json         â†’ Aggregate statistics                  â”‚
â”‚  â€¢ evidence_frames/     â†’ SVG snapshots of key events           â”‚
â”‚  â€¢ storyboard.json      â†’ Key moment thumbnails                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   REACT WEB INTERFACE                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â€¢ Interactive Demo     â†’ Real-time simulation with overlays    â”‚
â”‚  â€¢ EventTimeline        â†’ Visual compliance timeline            â”‚
â”‚  â€¢ PersonCropStrip      â†’ Multi-person analysis grid            â”‚
â”‚  â€¢ FrameViewer          â†’ Zoomable evidence inspection          â”‚
â”‚  â€¢ Live Metrics         â†’ Compliance/phone detection stats      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Project Structure

```
stairs-ai-demo/
â”œâ”€â”€ ğŸ“¦ assets/
â”‚   â””â”€â”€ preview.mp4              # 8-second demo video (1280Ã—720 @ 24fps)
â”‚
â”œâ”€â”€ ğŸ tools/                    # Python ML Pipeline
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ types.py             # Type definitions for all data structures
â”‚   â”‚   â”œâ”€â”€ masks.py             # Rail polygon hit-test manager
â”‚   â”‚   â”œâ”€â”€ pose.py              # MediaPipe pose estimation wrapper
â”‚   â”‚   â”œâ”€â”€ phone.py             # Phone detection heuristics
â”‚   â”‚   â”œâ”€â”€ state_machine.py    # Debounced state transitions
â”‚   â”‚   â”œâ”€â”€ overlay.py           # OpenCV visualization utilities
â”‚   â”‚   â”œâ”€â”€ events.py            # Event logging and evidence capture
â”‚   â”‚   â””â”€â”€ io.py                # JSON/JSONL serialization
â”‚   â”œâ”€â”€ run_demo.py              # Main inference pipeline
â”‚   â”œâ”€â”€ extract_storyboard.py    # Chapter thumbnail extraction
â”‚   â””â”€â”€ make_static_site_payload.py  # Generate web payload
â”‚
â”œâ”€â”€ âš›ï¸  web/                     # React Frontend
â”‚   â”œâ”€â”€ public/
â”‚   â”‚   â””â”€â”€ demo/                # Generated static payload
â”‚   â”‚       â”œâ”€â”€ events.json
â”‚   â”‚       â”œâ”€â”€ frame_packets.json
â”‚   â”‚       â”œâ”€â”€ summary.json
â”‚   â”‚       â”œâ”€â”€ evidence_frames/
â”‚   â”‚       â””â”€â”€ storyboard/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ lib/
â”‚   â”‚   â”‚   â”œâ”€â”€ types.ts         # TypeScript type definitions
â”‚   â”‚   â”‚   â”œâ”€â”€ format.ts        # Formatting utilities
â”‚   â”‚   â”‚   â””â”€â”€ demoData.ts      # Data loading hooks
â”‚   â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â”‚   â””â”€â”€ InteractiveDemo.tsx  # Main demo page
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ EventTimeline.tsx    # Visual timeline bar
â”‚   â”‚   â”‚   â”œâ”€â”€ PersonCropStrip.tsx  # Multi-person grid
â”‚   â”‚   â”‚   â”œâ”€â”€ FrameViewer.tsx      # Zoomable image viewer
â”‚   â”‚   â”‚   â”œâ”€â”€ MetricsCard.tsx      # Metric display cards
â”‚   â”‚   â”‚   â””â”€â”€ JsonViewer.tsx       # JSON data inspector
â”‚   â”‚   â”œâ”€â”€ App.tsx
â”‚   â”‚   â””â”€â”€ main.tsx
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ vite.config.ts
â”‚   â””â”€â”€ tailwind.config.js
â”‚
â”œâ”€â”€ ğŸ“„ rail_masks.json           # Handrail polygon coordinates
â”œâ”€â”€ ğŸ“‹ requirements.txt          # Python dependencies
â”œâ”€â”€ ğŸš€ .github/workflows/        # GitHub Actions CI/CD
â”‚   â””â”€â”€ deploy.yml               # Auto-deploy to GitHub Pages
â””â”€â”€ ğŸ“– README.md
```

---

## ğŸš€ Quick Start

### Prerequisites

- **Python 3.10+** (with pip)
- **Node.js 18+** (with npm)
- **Git** (for deployment)

### 1. Clone Repository

```bash
git clone https://github.com/YOUR_USERNAME/stairs-ai-demo.git
cd stairs-ai-demo
```

### 2. Run Python Pipeline (Optional)

```bash
# Install Python dependencies
pip install -r requirements.txt

# Run inference pipeline
python tools/run_demo.py --video assets/preview.mp4 --output web/public/demo

# Extract storyboard thumbnails
python tools/extract_storyboard.py
```

> **Note:** Pre-generated output is already included in `web/public/demo/`

### 3. Run Web Interface

```bash
cd web
npm install
npm run dev
```

Open browser to **http://localhost:3000/stairs-ai-demo/**

### 4. Build for Production

```bash
cd web
npm run build
```

Output will be in `web/dist/` ready for deployment.

---

## ğŸ® Interactive Demo Features

### ğŸ¥ **Video Simulation Player**
- Real-time animated simulation showing 4 compliance phases
- **Phase 1:** No rail contact, no phone â†’ **NON-COMPLIANT**
- **Phase 2:** Rail contact, no phone â†’ **COMPLIANT** âœ…
- **Phase 3:** Rail contact + phone â†’ **NON-COMPLIANT**
- **Phase 4:** No rail contact + phone â†’ **NON-COMPLIANT**

### ğŸ“Š **Pipeline Visualization**
- 8-stage pipeline cards showing active processing step
- Hover tooltips with configuration details
- Real-time stage progression indicator

### ğŸ¯ **Detection Details Panel**
- Per-person compliance status cards
- Rail contact indicators (âœ“ / âœ—)
- Phone detection alerts (ğŸ“±)
- Confidence scores and pose keypoint counts

### ğŸ“ˆ **Live Metrics Dashboard**
- Total persons detected
- Compliant count (green)
- Non-compliant count (red)
- Phone detection count (yellow)

### ğŸ“… **Interactive Timeline**
- Visual compliance bar (green/red)
- Phone detection bar (orange)
- Event markers with click-to-view
- Chapter headers for key moments
- Seekable timeline scrubber

### ğŸ‘¥ **Person Analysis Grid**
- Multi-person detection cards
- Border color indicates compliance status
- Status badges for rail contact (ğŸ¤š) and phone (ğŸ“±)
- Confidence scores and bbox dimensions

### ğŸ” **Evidence Frame Viewer**
- Click any event to open modal
- Zoomable evidence frames (0.5x - 3x)
- Download button for evidence snapshots
- Full event metadata display

### âš™ï¸ **Playback Controls**
- Play/Pause with large centered button
- Speed controls (0.5x, 1x, 2x)
- Reset to beginning
- Toggle overlays (bounding box, pose, rail mask)

---

## ğŸ› ï¸ Technology Stack

### Frontend
- **React 18** - UI framework
- **TypeScript 5** - Type-safe development
- **Vite 5** - Build tool and dev server
- **Tailwind CSS 3** - Utility-first styling
- **Lucide Icons** - Icon library
- **React Router 6** - Client-side routing

### Backend (Pipeline)
- **Python 3.10+** - Core language
- **OpenCV** - Video processing
- **YOLOv8 (Ultralytics)** - Object detection
- **MediaPipe** - Pose estimation
- **NumPy** - Numerical operations
- **Shapely** - Polygon geometry

### Deployment
- **GitHub Pages** - Static hosting
- **GitHub Actions** - CI/CD automation
- **Vite Build** - Production optimization

---

## ğŸ“¦ Data Flow

### Input Data
```
assets/preview.mp4  (8 seconds @ 24fps = 192 frames)
```

### Pipeline Output
```json
// frame_packets.json - Per-frame detection data
{
  "frame_number": 42,
  "timestamp_sec": 1.75,
  "metrics": {
    "total_persons": 1,
    "compliant_count": 1,
    "non_compliant_count": 0,
    "phone_count": 0
  },
  "persons": [...]
}

// events.json - State change events
{
  "event_id": "evt_002",
  "event_type": "compliant_start",
  "timestamp_sec": 2.5,
  "person_id": 1,
  "evidence_frame_path": "evidence_frames/frame_000060_compliant_start.svg"
}

// summary.json - Aggregate statistics
{
  "total_duration_sec": 8.0,
  "total_frames": 192,
  "total_events": 4,
  "compliance_rate": 0.37
}
```

---

## ğŸš¢ Deployment

### GitHub Pages (Automated)

1. **Push to GitHub:**
```bash
git add .
git commit -m "Initial commit"
git push origin main
```

2. **Enable GitHub Pages:**
- Go to repository Settings â†’ Pages
- Source: GitHub Actions
- The workflow will auto-deploy on push

3. **Access Live Demo:**
```
https://YOUR_USERNAME.github.io/stairs-ai-demo/
```

### Manual Build

```bash
cd web
npm run build
# Output in web/dist/ - deploy to any static host
```

---

## ğŸ“Š Pipeline Configuration

Edit `rail_masks.json` to adjust handrail detection zones:

```json
{
  "left_rail": {
    "polygon": [[30, 80], [90, 80], [90, 320], [30, 320]],
    "color": [34, 197, 94]
  },
  "right_rail": {
    "polygon": [[550, 80], [610, 80], [610, 320], [550, 320]],
    "color": [34, 197, 94]
  }
}
```

Adjust debounce timing in `tools/utils/state_machine.py`:

```python
DEBOUNCE_TIME = 0.55  # seconds
```

---

## ğŸ“ License

MIT License - See [LICENSE](LICENSE) file for details.

---

## ğŸ¤ Contributing

This is a portfolio demonstration project. For inquiries or collaboration:

- **GitHub Issues:** Report bugs or request features
- **Pull Requests:** Improvements welcome

---

## ğŸ“ Educational Use

This project demonstrates:
- Computer vision pipeline architecture
- Real-time pose estimation integration
- State machine design for temporal smoothing
- React component architecture
- TypeScript type safety in ML workflows
- Static site generation from ML outputs

Perfect for:
- ML portfolio presentations
- Computer vision education
- React + TypeScript learning
- CI/CD demonstration

---

## ğŸ”— Related Resources

- [YOLOv8 Documentation](https://docs.ultralytics.com/)
- [MediaPipe Pose](https://google.github.io/mediapipe/solutions/pose.html)
- [React Documentation](https://react.dev/)
- [Vite Guide](https://vitejs.dev/guide/)
- [Tailwind CSS](https://tailwindcss.com/)

---

**Built with â¤ï¸ for transparent, explainable AI systems**
